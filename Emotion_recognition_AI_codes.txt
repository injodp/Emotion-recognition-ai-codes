# foto maken voor dataset


import cv2  # OpenCV voor beeldverwerking
import os  # Bestandsbeheer
from datetime import datetime  # Tijd en datum voor bestandsnaam
from picamera2 import Picamera2  # Raspberry Pi camera
import time  # Voor vertragingen

def create_folder(name):
    """
    Functie om een map aan te maken voor een specifieke persoon.
    """
    dataset_folder = "dataset"  # Hoofdmap voor de dataset
    if not os.path.exists(dataset_folder):  # Check of map al bestaat
        os.makedirs(dataset_folder)  # Maak dataset-map aan
    
    person_folder = os.path.join(dataset_folder, name)  # Pad naar persoonsmap
    if not os.path.exists(person_folder):  # Check of persoonsmap al bestaat
        os.makedirs(person_folder)  # Maak persoonsmap aan
    return person_folder  # Geef het pad van de map terug

def capture_photos(name):
    """
    Functie om foto's te maken en op te slaan in de persoonsmap.
    """
    folder = create_folder(name)  # Haal de juiste opslagmap op
    
    picam2 = Picamera2()  # Initialiseer de Raspberry Pi-camera
    picam2.configure(picam2.create_preview_configuration(main={"format": 'XRGB8888', "size": (640, 480)}))  # Configureer de camera
    picam2.start()  # Start de camera
    
    time.sleep(2)  # Wacht even zodat de camera kan opstarten
    photo_count = 0  # Teller voor het aantal gemaakte foto's
    
    while True:
        frame = picam2.capture_array()  # Neem een foto en bewaar in een variabele
        cv2.imshow('Capture', frame)  # Toon het beeld in een venster
        key = cv2.waitKey(1) & 0xFF  # Wacht op een toetsdruk
        
        if key == ord(' '):  # Als spatiebalk wordt ingedrukt
            photo_count += 1  # Verhoog het aantal foto's
            filename = f"{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"  # Genereer bestandsnaam met datum/tijd
            filepath = os.path.join(folder, filename)  # Volledige bestandslocatie
            cv2.imwrite(filepath, frame)  # Sla de afbeelding op
            print(f"Photo {photo_count} saved: {filepath}")  # Print bevestiging in de terminal
        elif key == ord('q'):  # Als 'q' wordt ingedrukt, stop het programma
            break
    
    cv2.destroyAllWindows()  # Sluit het OpenCV-venster
    picam2.stop()  # Stop de camera

if __name__ == "__main__":
    capture_photos("person_name")  # Roep de functie aan met een naam als argument


# conversie code


import cv2  # OpenCV voor beeldverwerking
import os  # Bestandsbeheer
import numpy as np  # Werken met arrays
import pickle  # Opslaan van data in een binair formaat

def convert_images_to_pickle(dataset_folder, output_file):
    """
    Converteert afbeeldingen in de dataset naar een pickle-bestand.
    """
    data = {"encodings": [], "labels": []}  # Dictionary voor dataopslag
    
    for label in os.listdir(dataset_folder):  # Door alle submappen (labels) bladeren
        label_path = os.path.join(dataset_folder, label)  # Pad naar de map
        if not os.path.isdir(label_path):  # Controleer of het een map is
            continue  # Sla niet-mappen over
        
        for image_name in os.listdir(label_path):  # Door de afbeeldingen bladeren
            image_path = os.path.join(label_path, image_name)  # Volledige afbeeldingspad
            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Laad afbeelding in grijswaarden
            image = cv2.resize(image, (48, 48))  # Schaal afbeelding naar 48x48 pixels
            
            data["encodings"].append(image)  # Voeg afbeelding toe aan dataset
            data["labels"].append(label)  # Voeg label toe aan dataset
    
    with open(output_file, "wb") as f:  # Open het bestand in 'write binary' modus
        pickle.dump(data, f)  # Sla data op in een pickle-bestand

convert_images_to_pickle("dataset", "dataset.pickle")  # Voer conversie uit


# trainingsscript



import tensorflow as tf  # Machine learning framework
import numpy as np  # Werken met arrays
import pickle  # Laden van voorbewerkte data

def load_data(pickle_file):
    """
    Laadt gegevens uit een pickle-bestand en zet ze om in de juiste vorm.
    """
    with open(pickle_file, "rb") as f:  # Open het pickle-bestand
        data = pickle.load(f)  # Laad de data
        
    X = np.array(data["encodings"]).reshape(-1, 48, 48, 1) / 255.0  # Normaliseer en herschik de data
    y = np.array(data["labels"])  # Laad de labels
    return X, y  # Geef de gegevens terug

X, y = load_data("dataset.pickle")  # Laad de dataset

# Modeldefinitie
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),  # Eerste Convolutielaag
    tf.keras.layers.MaxPooling2D((2,2)),  # Max pooling laag
    tf.keras.layers.Flatten(),  # Flatten de data voor de Dense lagen
    tf.keras.layers.Dense(128, activation='relu'),  # Verborgen laag met 128 neuronen
    tf.keras.layers.Dense(len(set(y)), activation='softmax')  # Outputlaag, afhankelijk van het aantal klassen
])

# Compileer en train het model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(X, y, epochs=10, validation_split=0.2)  # Train het model met validatiesplitsing

model.save("emotion_recognition_custom_model.h5")  # Sla het getrainde model op


# live detection


import face_recognition  # Gezichtsherkenning
import cv2  # OpenCV voor beeldverwerking
import numpy as np  # Werken met arrays
from picamera2 import Picamera2  # Raspberry Pi camera
import tensorflow as tf  # Machine learning framework
import pickle  # Laden van opgeslagen data

# Laad gezichtsherkenningsdata
with open("encodings.pickle", "rb") as f:
    data = pickle.loads(f.read())
known_face_encodings = data["encodings"]
known_face_names = data["names"]

# Laad het emotieherkenningsmodel
emotion_model = tf.keras.models.load_model("emotion_recognition_custom_model.h5")
emotion_labels = ['happy', 'sad', 'angry', 'neutral']  # Emotie labels

# Start de camera
picam2 = Picamera2()
picam2.configure(picam2.create_preview_configuration(main={"format": 'XRGB8888', "size": (640, 480)}))
picam2.start()

while True:
    frame = picam2.capture_array()  # Haal frame op
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Converteer naar RGB
    face_locations = face_recognition.face_locations(rgb_frame)  # Detecteer gezichten
    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)  # Encode gezichten

    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
        name = "Unknown"
        
        if True in matches:
            best_match_index = np.argmin(face_recognition.face_distance(known_face_encodings, face_encoding))
            name = known_face_names[best_match_index]

        label = f"{name}"
        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

    cv2.imshow("Face and Emotion Recognition", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cv2.destroyAllWindows()
picam2.stop()
